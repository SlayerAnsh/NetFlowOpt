{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2ee9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import shutil\n",
    "import psutil\n",
    "import gc\n",
    "import re\n",
    "import random\n",
    "import csv\n",
    "import numpy\n",
    "import collections\n",
    "import subprocess\n",
    "import matplotlib.pyplot as matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import logging\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logg = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926d0a4",
   "metadata": {},
   "source": [
    "# Utilities Classes Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa650af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportedFileTypes:\n",
    "    JSON = \"json\"\n",
    "    MATLAB = \"m\"\n",
    "    OCTAVE = \"octave\"\n",
    "    TXT = \"txt\"\n",
    "    R = \"r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportedDistributions:\n",
    "    DISCRETE = \"discrete\"\n",
    "    GAUSS = \"gauss\"\n",
    "    UNIFORM = \"uniform\"\n",
    "    GAMMA = \"gamma\"\n",
    "    LOGNORMAL = \"lognormal\"\n",
    "    BINOMIAL = \"binomial\"\n",
    "    POISSON = \"poisson\"\n",
    "    BOOLEAN = \"boolean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportedAnalysisTypes:\n",
    "    CLASSIFICATION = \"CLASSIFICATION\"\n",
    "    REGRESSION = \"REGRESSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd207549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportedThirdPartyResponses:\n",
    "    INTEGER = int\n",
    "    VECTOR = list\n",
    "    FLOAT = float\n",
    "    STRING = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeCastUtil(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def safeCast(val, to_type, default=None):\n",
    "        try:\n",
    "            return to_type(val)\n",
    "        except (ValueError, TypeError):\n",
    "            return default\n",
    "\n",
    "    @staticmethod\n",
    "    def getMatrixShapeNullSafe(matrix):\n",
    "        matrix_shape = matrix.shape\n",
    "        if len(matrix_shape) == 1:\n",
    "            return matrix_shape[0], 1\n",
    "        elif len(matrix_shape) > 1:\n",
    "            return matrix_shape\n",
    "        else:\n",
    "            return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29611165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GarbageCollectionUtility(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def logMemoryUsageAndGarbageCollect(log):\n",
    "        processes = psutil.Process()\n",
    "        procs = [processes] + processes.children(recursive=True)\n",
    "        for process in procs:\n",
    "            rss = process.memory_info().rss\n",
    "            memory_usage_mb = numpy.round(rss / 1e6, 2)\n",
    "            log.info(\"Memory usage for PID %s: %s: MB\", process.pid, memory_usage_mb)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperatingSystemUtil(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def changeWorkingDirectory(new_directory):\n",
    "        if not os.path.isdir(new_directory):\n",
    "            os.mkdir(new_directory)\n",
    "        os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf70567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileProcessingService(object):\n",
    "\n",
    "    GENERATED_FOLDER_NAME = \"/GenomeFiles\"\n",
    "    GENOMES_FILE_NAME = \"Genomes.txt\"\n",
    "    IDENTIFIER_REGEX = re.compile(r'\\$.+?\\$')\n",
    "    DEFAULT_GAUSSIAN_STANDARD_DEVIATION = 0.1\n",
    "    OUTPUT_FILE_NAME = \"Sim0GenomesMatrix.csv\"\n",
    "\n",
    "    DEFAULT_NUM_GENOMES = 10\n",
    "\n",
    "    num_generated_coefficients = 0\n",
    "\n",
    "    def __init__(self, data_file, file_type, number_of_genomes, path):\n",
    "        self.data_file = data_file\n",
    "        self.file_type = file_type\n",
    "        self.number_of_genomes = SafeCastUtil.safeCast(number_of_genomes, int, self.DEFAULT_NUM_GENOMES)\n",
    "        self.path = path\n",
    "\n",
    "    def createGenomes(self):\n",
    "        if self.file_type == SupportedFileTypes.MATLAB or self.file_type == SupportedFileTypes.OCTAVE:\n",
    "            return self.handleFile(\"%\")\n",
    "        elif self.file_type == SupportedFileTypes.R:\n",
    "            return self.handleFile(\"#\")\n",
    "            # Note - fn will need to be able to take in files containing booleans\n",
    "\n",
    "    def handleFile(self, comment_character, file_name_root=\"genome\"):\n",
    "        genomes_file_list = []\n",
    "\n",
    "        path = self.maybeCreateNewFileDirectory()\n",
    "\n",
    "        genomes = collections.OrderedDict()\n",
    "        for genome in range(1, self.number_of_genomes + 1):\n",
    "            genome_name = file_name_root + str(genome) #Note - changed this to a parameter for SIM1\n",
    "            coefficient_map = collections.OrderedDict()\n",
    "            new_genome_file = open(path + \"/\" + genome_name + \".\" + self.file_type, \"w\")\n",
    "            genomes_file_list.append(genome_name + \".\" + self.file_type)\n",
    "\n",
    "            for line in self.data_file:\n",
    "                if line[0] == comment_character:\n",
    "                    new_genome_file.write(line)\n",
    "                    continue\n",
    "                new_line = self.maybeGenerateNewLineAndSaveCoefficientValues(coefficient_map, line)\n",
    "                new_genome_file.write(new_line)\n",
    "            new_genome_file.close()\n",
    "\n",
    "            self.data_file.seek(0)\n",
    "            self.num_generated_coefficients = 0\n",
    "            genomes[genome_name] = coefficient_map\n",
    "\n",
    "        self.writeGenomesKeyFilesToDirectory(genomes, path)\n",
    "        genomes_matrix = self.createGenomesMatrix(genomes)\n",
    "        self.writeDataFile(genomes_matrix)\n",
    "        return [genomes_file_list, genomes_matrix]\n",
    "\n",
    "    def maybeCreateNewFileDirectory(self):\n",
    "        target_directory = self.path + self.GENERATED_FOLDER_NAME\n",
    "        if os.getcwd() != \"/\":\n",
    "            if not os.path.isdir(target_directory):\n",
    "                os.mkdir(target_directory)\n",
    "        else:\n",
    "            raise ValueError('Provided path must not be root directory.')\n",
    "        return target_directory\n",
    "\n",
    "    def maybeGenerateNewLineAndSaveCoefficientValues(self, coefficient_map, line):\n",
    "        target_sequences = self.extractTargetSequences(line)\n",
    "        new_line = line\n",
    "        for i in range(0, len(target_sequences)):\n",
    "            target_sequence = target_sequences[i]\n",
    "            coefficient_name = self.extractCoefficientName(target_sequence)\n",
    "            distribution = self.extractDistributionName(target_sequence)\n",
    "            params = self.extractParameters(target_sequence)\n",
    "            coefficient_value = self.retrieveCoefficientValueFromDistribution(distribution, params)\n",
    "\n",
    "            # Replace $dollar sign contents$ with extracted coefficient value, write to file\n",
    "            new_line = new_line.replace(\"$\" + target_sequence + \"$\", str(coefficient_value), 1)\n",
    "            if type(coefficient_value) is str:\n",
    "                coefficient_value = self.replaceCoefValue(coefficient_value)\n",
    "            coefficient_map[coefficient_name] = coefficient_value\n",
    "        return new_line\n",
    "\n",
    "    def extractTargetSequences(self, line):\n",
    "        return [target_sequence.replace(\"$\", \"\") for target_sequence in self.IDENTIFIER_REGEX.findall(line)]\n",
    "\n",
    "    def extractCoefficientName(self, target_sequence):\n",
    "        if \"name=\" in target_sequence:\n",
    "            return target_sequence.split(\"name=\")[1].strip()\n",
    "        else:\n",
    "            self.num_generated_coefficients += 1\n",
    "            return \"coefficient\" + str(self.num_generated_coefficients)\n",
    "\n",
    "    def extractDistributionName(self, target_sequence):\n",
    "        distribution_name = ''\n",
    "        if \"name=\" in target_sequence or (\"(\" in target_sequence and \")\" in target_sequence):\n",
    "            distribution_name = re.findall(r'[a-z]*', target_sequence.split(\"name=\")[0])[0]\n",
    "\n",
    "        elif \"name=\" not in target_sequence and (\"(\" in target_sequence and \")\" in target_sequence):\n",
    "            distribution_name = re.findall(r'[a-z]*', target_sequence)[0]\n",
    "\n",
    "        if distribution_name == '':\n",
    "            return SupportedDistributions.GAUSS\n",
    "        else:\n",
    "            return distribution_name\n",
    "\n",
    "    def extractParameters(self, target_sequence):\n",
    "        pattern = re.compile('-? *\\.?[0-9]+\\.?[0-9]*(?:[Ee] *-? *[0-9]+)?')  # now supports scientific notation\n",
    "        return [param.strip() for param in re.findall(pattern, target_sequence.split(\"name=\")[0])]\n",
    "\n",
    "    def retrieveCoefficientValueFromDistribution(self, distribution, params):\n",
    "        # Selection from a series of both discrete and continuous probability distributions\n",
    "        if distribution == SupportedDistributions.UNIFORM:\n",
    "            return self.generateRandomValueFromUniformDistribution(params[0], params[1])\n",
    "        elif distribution == SupportedDistributions.GAUSS:  # changed form GAUSSIAN TO GAUSS\n",
    "            if len(params) <= 1:\n",
    "                return self.generateRandomValueFromGaussianDistribution(params[0],\n",
    "                                                                        self.DEFAULT_GAUSSIAN_STANDARD_DEVIATION * float(params[0]))\n",
    "            else:\n",
    "                return self.generateRandomValueFromGaussianDistribution(params[0], params[1])\n",
    "        elif distribution == SupportedDistributions.DISCRETE:\n",
    "            return self.generateRandomValueFromDiscreteDistribution(params)\n",
    "        elif distribution == SupportedDistributions.GAMMA:\n",
    "            return self.generateRandomValueFromGammaDistribution(params[0], params[1])\n",
    "        elif distribution == SupportedDistributions.LOGNORMAL:\n",
    "            return self.generateRandomValueFromLogNormalDistribution(params[0], params[1])\n",
    "        elif distribution == SupportedDistributions.BINOMIAL:\n",
    "            return self.generateRandomValueFromBinomialDistribution(params[0], params[1])\n",
    "        elif distribution == SupportedDistributions.POISSON:\n",
    "            return self.generateRandomValueFromPoissonDistribution(params[0])\n",
    "        elif distribution == SupportedDistributions.BOOLEAN:\n",
    "            return self.pickBoolean(params[0])\n",
    "        else:\n",
    "            raise ValueError('Unsupported distribution: ' + distribution)\n",
    "\n",
    "    def generateRandomValueFromUniformDistribution(self, mini, maxi):\n",
    "        return random.uniform(SafeCastUtil.safeCast(mini, float, -1), SafeCastUtil.safeCast(maxi, float, 1))\n",
    "\n",
    "    def generateRandomValueFromGaussianDistribution(self, mu, sigma):\n",
    "        return random.gauss(SafeCastUtil.safeCast(mu, float, 0), SafeCastUtil.safeCast(sigma, float, 1))\n",
    "\n",
    "    def generateRandomValueFromDiscreteDistribution(self, values):\n",
    "        return SafeCastUtil.safeCast(random.choice(values), float, 0)\n",
    "\n",
    "    def generateRandomValueFromGammaDistribution(self, k, theta):\n",
    "        return random.gammavariate(SafeCastUtil.safeCast(k, float, 1), SafeCastUtil.safeCast(theta, float, 1))\n",
    "\n",
    "    def generateRandomValueFromLogNormalDistribution(self, mu, sigma):\n",
    "        return random.lognormvariate(SafeCastUtil.safeCast(mu, float, 0), SafeCastUtil.safeCast(sigma, float, 1))\n",
    "\n",
    "    def generateRandomValueFromBinomialDistribution(self, n, p):\n",
    "        return numpy.random.binomial(SafeCastUtil.safeCast(n, int, 100), SafeCastUtil.safeCast(p, float, 0.5))\n",
    "\n",
    "    def generateRandomValueFromPoissonDistribution(self, k):\n",
    "        return numpy.random.poisson(SafeCastUtil.safeCast(k, int, 1))\n",
    "\n",
    "    def pickBoolean(self, probability_of_zero):\n",
    "        val = random.uniform(0, 1)\n",
    "        if val < SafeCastUtil.safeCast(probability_of_zero, float, 0.6):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def writeGenomesKeyFilesToDirectory(self, genomes, path):\n",
    "        for genome in genomes.keys():\n",
    "            key_file_extension = self.file_type\n",
    "            if key_file_extension == SupportedFileTypes.OCTAVE:\n",
    "                key_file_extension = SupportedFileTypes.MATLAB\n",
    "            new_genome_file = open(path + \"/\" + genome + \"_key.\" + key_file_extension, \"w\")\n",
    "            for value in genomes[genome].keys():\n",
    "                if self.file_type == SupportedFileTypes.MATLAB or SupportedFileTypes.OCTAVE:\n",
    "                    new_genome_file.write(str(value) + \"=\" + str(genomes[genome][value]) + \";\" + \"\\n\")\n",
    "                elif self.file_type == SupportedFileTypes.R:\n",
    "                    new_genome_file.write(str(value) + \"<-\" + str(genomes[genome][value]) + \"\\n\")\n",
    "            new_genome_file.close()\n",
    "\n",
    "    def createGenomesMatrix(self, genomes):\n",
    "        genomes_matrix = []\n",
    "        counter = 0\n",
    "        for genome in genomes.keys():\n",
    "            genomes_matrix.append([])\n",
    "            for value in genomes[genome].keys():\n",
    "                genomes_matrix[counter].append((genomes[genome][value]))\n",
    "            counter = counter + 1\n",
    "        return genomes_matrix\n",
    "\n",
    "    def replaceCoefValue(self, coefficient_string):\n",
    "        if coefficient_string == \"\":\n",
    "            return int(-1)\n",
    "        else:\n",
    "            pos = coefficient_string.index(\")\")\n",
    "            return int(coefficient_string[pos - 1])\n",
    "\n",
    "    def writeDataFile(self, genomes_matrix):\n",
    "        current_directory = os.getcwd()\n",
    "        OperatingSystemUtil.changeWorkingDirectory(self.path + \"/GenomeFiles\")\n",
    "        with open(self.OUTPUT_FILE_NAME, 'w') as csv_file:\n",
    "            try:\n",
    "                data_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                for i in range(0, self.number_of_genomes):\n",
    "                    data_writer.writerow(genomes_matrix[i])\n",
    "            finally:\n",
    "                csv_file.close()\n",
    "                OperatingSystemUtil.changeWorkingDirectory(current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sim1FileProcessingService(FileProcessingService):\n",
    "\n",
    "    GENOMES_KEY_FILE_REGEX = re.compile(r'genome(\\d+)?')\n",
    "    DEFAULT_NUM_TRIALS = 100\n",
    "\n",
    "    def __init__(self, u_file_instance, file_type, number_of_genomes, number_of_trials, path=os.getcwd()):\n",
    "        self.number_of_trials = SafeCastUtil.safeCast(number_of_trials, int, self.DEFAULT_NUM_TRIALS)\n",
    "        # Note r_trials is analogous to permutations\n",
    "        FileProcessingService.__init__(self, u_file_instance, file_type, number_of_genomes, path)\n",
    "\n",
    "    def createTrialFiles(self):\n",
    "        if self.file_type == SupportedFileTypes.MATLAB or self.file_type == SupportedFileTypes.OCTAVE:\n",
    "            return self.handleSim1FileProcessing(\"%\")\n",
    "        elif self.file_type == SupportedFileTypes.R:\n",
    "            return self.handleSim1FileProcessing(\"#\")\n",
    "\n",
    "    def handleSim1FileProcessing(self, comment_character):\n",
    "        '''\n",
    "        Creates r_trials of type self.file_type files with $distribution(a,b),name=x$ replaced with values\n",
    "        Also creates TrialCallFile, which calls each of the R generated .m values\n",
    "        :return: sim1_file_list --> list of names of all files created\n",
    "        '''\n",
    "        sim1_file_list = []\n",
    "        path = self.maybeCreateNewFileDirectory()\n",
    "\n",
    "        for trial in range(1, self.number_of_trials + 1):\n",
    "            coefficient_map = collections.OrderedDict()\n",
    "            trial_name = 'trial' + str(trial)  # Note - T\n",
    "            new_trial_file = open(path + \"/\" + trial_name + \"_genome1.\" + self.file_type, \"w\")\n",
    "            sim1_file_list.append(trial_name + \"_genome1.\" + self.file_type)\n",
    "            for line in self.data_file.readlines():\n",
    "                if line[0] == comment_character:\n",
    "                    new_trial_file.write(line)\n",
    "                    continue\n",
    "                new_line = self.maybeGenerateNewLineAndSaveCoefficientValues(coefficient_map, line)\n",
    "                new_trial_file.write(new_line)\n",
    "\n",
    "            new_trial_file.close()\n",
    "            self.data_file.seek(0)\n",
    "            for genome in range(2, self.number_of_genomes + 1):\n",
    "                genome_name = 'genome' + str(genome)\n",
    "                new_trial_genome_file = open(path + \"/\" + trial_name + \"_\" + genome_name + \".\" + self.file_type, \"w\")\n",
    "                # Writing file name to python list\n",
    "                sim1_file_list.append(trial_name + \"_\" + genome_name + \".\" + self.file_type)\n",
    "                trial_file = open(path + \"/\" + trial_name + \"_genome1.\" + self.file_type, \"r\")\n",
    "                for line in trial_file.readlines():\n",
    "                    if line[0] == comment_character:\n",
    "                        new_trial_genome_file.write(line)\n",
    "                        continue\n",
    "                    search_result_for_genomes_file = self.GENOMES_KEY_FILE_REGEX.search(line)\n",
    "                    if search_result_for_genomes_file is not None:\n",
    "                        new_line = self.GENOMES_KEY_FILE_REGEX.sub(genome_name, line)\n",
    "                        new_trial_genome_file.write(new_line)\n",
    "                    else:\n",
    "                        new_trial_genome_file.write(line)\n",
    "                new_trial_genome_file.close()\n",
    "                self.data_file.seek(0)\n",
    "        return sim1_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThirdPartyProgramCaller(object):\n",
    "\n",
    "    log = logging.getLogger(__name__)\n",
    "    logging.basicConfig()\n",
    "    log.setLevel(logging.INFO)\n",
    "    SIM0OUTPUT_FILE_NAME = 'Sim0Output'\n",
    "    SIM1OUTPUT_FILE_NAME = 'Sim1'\n",
    "    OUTPUT_FOLDER_NAME = \"/SimulationOutputs\"\n",
    "\n",
    "    def __init__(self, files_directory, file_type, file_list, response_type, number_of_genomes, number_of_trials=0):\n",
    "        self.files_directory = files_directory\n",
    "        self.file_type = file_type\n",
    "        self.file_list = file_list\n",
    "        self.counter = 0\n",
    "        self.number_of_genomes = int(number_of_genomes)\n",
    "        self.number_of_trials = int(number_of_trials)\n",
    "        if type(response_type) is str:\n",
    "            self.response_type = eval(response_type)\n",
    "        else:\n",
    "            self.response_type = response_type\n",
    "\n",
    "    def callThirdPartyProgram(self, should_write_sim0_output):\n",
    "        current_directory = os.getcwd()\n",
    "        directory_of_files = self.files_directory + \"/GenomeFiles\"\n",
    "        OperatingSystemUtil.changeWorkingDirectory(directory_of_files)\n",
    "        outputs = collections.OrderedDict()\n",
    "        if self.file_type == SupportedFileTypes.MATLAB:\n",
    "            try:\n",
    "                import matlab.engine\n",
    "                outputs = self.callMatlabAPI(outputs)\n",
    "            except ImportError as error:\n",
    "                self.log.warn(\"Unable to find MATLAB API hook. Starting program once per trial file.\\n%s\", error)\n",
    "                for file in self.file_list:\n",
    "                    self.logAndIncrementProgress()\n",
    "                    file_result = self.callMATLAB(directory_of_files, file)\n",
    "                    outputs[file.split(\".\")[0]] = file_result\n",
    "                    if self.number_of_trials != 0:\n",
    "                        output_file_name = self.SIM1OUTPUT_FILE_NAME + '_' + file.split(\".\")[0]\n",
    "                        self.writeOutputFile(file_result, output_file_name)\n",
    "                        self.writeSim1Matrix(outputs)\n",
    "        elif self.file_type == SupportedFileTypes.R:\n",
    "            for file in self.file_list:\n",
    "                self.logAndIncrementProgress()\n",
    "                file_result = self.callR(directory_of_files, file)\n",
    "                outputs[file.split(\".\")[0]] = file_result\n",
    "                if self.number_of_trials != 0:\n",
    "                    output_file_name = self.SIM1OUTPUT_FILE_NAME + '_' + file.split(\".\")[0]\n",
    "                    self.writeOutputFile(file_result, output_file_name)\n",
    "                    self.writeSim1Matrix(outputs)\n",
    "        elif self.file_type == SupportedFileTypes.OCTAVE:\n",
    "            for file in self.file_list:\n",
    "                self.logAndIncrementProgress()\n",
    "                file_result = self.callOctave(directory_of_files, file)\n",
    "                outputs[file.split(\".\")[0]] = file_result\n",
    "                if self.number_of_trials != 0:\n",
    "                    output_file_name = self.SIM1OUTPUT_FILE_NAME + '_' + file.split(\".\")[0]\n",
    "                    self.writeOutputFile(file_result, output_file_name)\n",
    "                    self.writeSim1Matrix(outputs)\n",
    "        if should_write_sim0_output:\n",
    "            output_list = []\n",
    "            for file in outputs.keys():\n",
    "                output_list.append(outputs[file])\n",
    "            self.writeOutputFile(output_list, self.SIM0OUTPUT_FILE_NAME)\n",
    "        elif self.number_of_trials != 0:\n",
    "            sim1matrix_service = MatrixService(outputs, self.number_of_genomes, self.number_of_trials)\n",
    "            sim1matrix_service.generateSimilarityMatrix('final')\n",
    "            if self.response_type == SupportedThirdPartyResponses.FLOAT or self.response_type == SupportedThirdPartyResponses.INTEGER:\n",
    "                sim1matrix_service.generateResponseMatrix()\n",
    "        OperatingSystemUtil.changeWorkingDirectory(current_directory)\n",
    "        return outputs\n",
    "\n",
    "    def logAndIncrementProgress(self):\n",
    "        self.log.info(str(100 * self.counter / len(self.file_list)) + \"% complete\")\n",
    "        self.counter += 1\n",
    "\n",
    "    def writeOutputFile(self, outputs, output_file_name):\n",
    "        if type(outputs) != list:\n",
    "            outputs = [outputs]\n",
    "        path = os.getcwd()\n",
    "        OperatingSystemUtil.changeWorkingDirectory(path + self.OUTPUT_FOLDER_NAME)\n",
    "        file_name = output_file_name + \".csv\"\n",
    "        with open(file_name, 'w') as csv_file:\n",
    "            try:\n",
    "                outputs_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                outputs_writer.writerow(outputs)\n",
    "            except ValueError as error:\n",
    "                self.log.error(\"Error writing %s to file %s. %s\", outputs, file_name, error)\n",
    "            finally:\n",
    "                csv_file.close()\n",
    "                os.chdir(path)\n",
    "\n",
    "    def callOctave(self, directory_of_file, call_file):\n",
    "        cmd = 'octave -q ' + directory_of_file + \"/\" + call_file\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True, universal_newlines=True)\n",
    "        (out, err) = proc.communicate()\n",
    "        self.log.info(\"Output result from file %s: %s\", call_file, out)\n",
    "        output = out.strip()\n",
    "        output = output.split()\n",
    "        output = self.reshapeOutput(output)\n",
    "        return output\n",
    "\n",
    "    def callMatlabAPI(self, outputs):\n",
    "        import matlab.engine\n",
    "        self.log.info('Using the matlab api hook')\n",
    "        eng = matlab.engine.start_matlab('-nojvm -nodisplay -nosplash -nodesktop')\n",
    "        for file in self.file_list:\n",
    "            file_name = file.split(\".\")[0]\n",
    "            eng.eval(file_name, nargout=0)\n",
    "            output = eng.workspace['output']\n",
    "            outputs[file_name] = output\n",
    "            self.logAndIncrementProgress()\n",
    "            if self.number_of_trials != 0:\n",
    "                output_file_name = self.SIM1OUTPUT_FILE_NAME + '_' + file_name\n",
    "                self.writeOutputFile(output, output_file_name)\n",
    "                self.writeSim1Matrix(outputs)\n",
    "        eng.quit()\n",
    "        return outputs\n",
    "\n",
    "    def callMATLAB(self, directory_of_file, call_file):\n",
    "        cmd = 'matlab -nojvm -nodisplay -nosplash -nodesktop <' + directory_of_file + \"/\" + call_file\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True, universal_newlines=True)\n",
    "        (out, err) = proc.communicate()\n",
    "\n",
    "        first = out.index(\"[\")\n",
    "        second = out.index(\"]\")\n",
    "        self.logAndIncrementProgress()\n",
    "\n",
    "        output = out[first + 1:second]\n",
    "        output = output.strip()\n",
    "        output = output.split()\n",
    "        output = self.reshapeOutput(output)\n",
    "        return output\n",
    "\n",
    "    def callR(self, directory_of_file, call_file):\n",
    "        cmd = 'Rscript ' + directory_of_file + \"/\" + call_file\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True, universal_newlines=True)\n",
    "        (out, err) = proc.communicate()\n",
    "\n",
    "        try:\n",
    "            pos = out.index(\"]\")\n",
    "        except ValueError as value_error:\n",
    "            self.log.error(\"Error processing R file %s: %s. Returned output: %s\", call_file, value_error, out)\n",
    "            return -1\n",
    "        output = SafeCastUtil.safeCast(out[pos + 2], self.response_type)\n",
    "        if self.response_type == SupportedThirdPartyResponses.VECTOR:\n",
    "            avg_vector_split = out.split(\"%avg%\")\n",
    "            return [SafeCastUtil.safeCast(sub, float) for sub in\n",
    "                    avg_vector_split if type(SafeCastUtil.safeCast(sub, float)) is float]\n",
    "        return output\n",
    "\n",
    "    def writeSim1Matrix(self, outputs, min_num_of_trials=2):\n",
    "        current_trials = (self.counter//self.number_of_genomes)\n",
    "        if (self.counter % (1 * self.number_of_genomes) == 0) and (current_trials > min_num_of_trials):\n",
    "            sim1matrix_service = MatrixService(outputs, self.number_of_genomes, current_trials)\n",
    "            self.log.info('Writing similarity matrix based on %s trials.', str(current_trials))\n",
    "            sim1matrix_service.generateSimilarityMatrix(str(current_trials))\n",
    "\n",
    "    def reshapeOutput(self, output):\n",
    "        if len(output) == 1:\n",
    "            try:\n",
    "                return SafeCastUtil.safeCast(output[0], self.response_type)\n",
    "            except TypeError as type_error:\n",
    "                self.log.error(type_error)\n",
    "                return self.response_type(-1)\n",
    "        else:\n",
    "            try:\n",
    "                t = int(output[0])\n",
    "                n = int(output[1])\n",
    "                output = output[2:]\n",
    "                output = [float(i) for i in output]\n",
    "                assert ((n * t) == len(output))\n",
    "                response_vector = np.array(output).reshape((t, n))  # reconstruct the original matrix\n",
    "                return response_vector.tolist()\n",
    "            except TypeError as type_error:\n",
    "                self.log.error(type_error)\n",
    "                return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphingService(object):\n",
    "\n",
    "    log = logging.getLogger(__name__)\n",
    "    logging.basicConfig()\n",
    "    log.setLevel(logging.INFO)\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    DEFAULT_PLOT_FILENAME = \"MachineLearningMultiBarPlot\"\n",
    "    COLOR_PROGRESSION = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "\n",
    "    def makeMultiBarPlotWithMultipleAnalysis(self, full_data, output_path, analysis_type, title):\n",
    "        basic_plot = matplotlib.figure()\n",
    "\n",
    "        full_data_sorted_by_percentage = self.sortByPercentage(full_data)\n",
    "\n",
    "        location_on_plot = 1\n",
    "        x_ticks = []\n",
    "\n",
    "        for percentage in full_data_sorted_by_percentage.keys():\n",
    "            data = full_data_sorted_by_percentage[percentage].values()\n",
    "            keys = full_data_sorted_by_percentage[percentage].keys()\n",
    "            positions = SafeCastUtil.safeCast(range(location_on_plot, location_on_plot + len(keys)), list)\n",
    "            plot = matplotlib.boxplot(data, positions=positions, widths=0.6)\n",
    "            self.color_by_analysis(keys, plot)\n",
    "            x_ticks.append(location_on_plot + (len(keys) / 2))\n",
    "            location_on_plot += 4\n",
    "\n",
    "        matplotlib.title(title)\n",
    "\n",
    "        # set axes limits and labels\n",
    "        if analysis_type == SupportedAnalysisTypes.CLASSIFICATION:\n",
    "            matplotlib.ylim(0, 1)\n",
    "        else:\n",
    "            matplotlib.ylim(-1, 1)\n",
    "        matplotlib.ylabel(\"Accuracy distribution\")\n",
    "\n",
    "        matplotlib.xlim(0, location_on_plot - 1)\n",
    "        matplotlib.xlabel(\"% Train\")\n",
    "        matplotlib.xticks(x_ticks, [SafeCastUtil.safeCast(k*100, int) for k in full_data_sorted_by_percentage.keys()])\n",
    "        self.createLegend(full_data)\n",
    "\n",
    "        basic_plot.show()\n",
    "\n",
    "        current_path = os.getcwd()\n",
    "        OperatingSystemUtil.changeWorkingDirectory(output_path)\n",
    "        basic_plot.savefig(self.DEFAULT_PLOT_FILENAME + title, bbox_inches='tight')\n",
    "        OperatingSystemUtil.changeWorkingDirectory(current_path)\n",
    "\n",
    "    def sortByPercentage(self, full_data):\n",
    "        by_percentage = {}\n",
    "        for analysis_type in full_data.keys():\n",
    "            for percentage_data in full_data[analysis_type].keys():\n",
    "                if percentage_data not in by_percentage.keys():\n",
    "                    by_percentage[percentage_data] = {analysis_type: full_data[analysis_type][percentage_data]}\n",
    "                else:\n",
    "                    by_percentage[percentage_data][analysis_type] = full_data[analysis_type][percentage_data]\n",
    "        return by_percentage\n",
    "\n",
    "    def color_by_analysis(self, keys, plot):\n",
    "        for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "            if len(keys) != 0 and len(plot[element]) % len(keys) == 0:\n",
    "                color_split = SafeCastUtil.safeCast(len(plot[element]) / len(keys), int)\n",
    "                i = 0\n",
    "                color_index = 0\n",
    "                while i < len(plot[element]):\n",
    "                    if i % color_split == 0 and i > 0:\n",
    "                        color_index += 1\n",
    "                        if color_split >= len(self.COLOR_PROGRESSION):\n",
    "                            color_index = 0\n",
    "                    matplotlib.setp(plot[element][i], color=self.COLOR_PROGRESSION[color_index])\n",
    "                    i += 1\n",
    "\n",
    "    def createLegend(self, full_data):\n",
    "        patches = []\n",
    "        color_index = 0\n",
    "        for key in full_data.keys():\n",
    "            if color_index >= len(self.COLOR_PROGRESSION):\n",
    "                color_index = 0\n",
    "            patch = mpatches.Patch(color=self.COLOR_PROGRESSION[color_index], label=key)\n",
    "            patches.append(patch)\n",
    "            color_index += 1\n",
    "        matplotlib.legend(handles=patches, loc=4)\n",
    "\n",
    "# Required Citation (BibTex/LaTex):\n",
    "# @Article{Hunter:2007,\n",
    "#   Author    = {Hunter, J. D.},\n",
    "#   Title     = {Matplotlib: A 2D graphics environment},\n",
    "#   Journal   = {Computing In Science \\& Engineering},\n",
    "#   Volume    = {9},\n",
    "#   Number    = {3},\n",
    "#   Pages     = {90--95},\n",
    "#   abstract  = {Matplotlib is a 2D graphics package used for Python\n",
    "#   for application development, interactive scripting, and\n",
    "#   publication-quality image generation across user\n",
    "#   interfaces and operating systems.},\n",
    "#   publisher = {IEEE COMPUTER SOC},\n",
    "#   doi = {10.1109/MCSE.2007.55},\n",
    "#   year      = 2007\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixService(object):\n",
    "    \n",
    "    OUTPUT_FILE_NAME = \"Sim1SimilarityMatrix\"\n",
    "    SIM1_OUTPUT_FILE_NAME = \"Sim1Responses.csv\"\n",
    "    OUTPUT_FOLDER_NAME = \"/SimilarityMatrix\"\n",
    "\n",
    "    #TODO Add the inputs for weight_vector\n",
    "    def __init__(self, simulation_result, number_of_genomes, number_of_trials):\n",
    "        self.simulation_result = simulation_result\n",
    "        self.number_of_genomes = int(number_of_genomes)\n",
    "        self.number_of_trials = int(number_of_trials)\n",
    "        self.list_of_maximum = []\n",
    "\n",
    "    def generateSimilarityMatrix(self, output_trials=''):\n",
    "        response_list = self.generateResponseList()\n",
    "        if (type(response_list[0]) == int) or (type(response_list[0]) == float):\n",
    "            output_type = 'scalar'\n",
    "        else:\n",
    "            output_type = 'vector'\n",
    "            response_list = np.array(response_list)\n",
    "        index_matrix = self.generateIndexMatrix()\n",
    "        similarity_matrix = self.computeSimilarityScores(response_list, index_matrix, output_type, weight_vector=None)\n",
    "        self.writeDataFile(similarity_matrix, self.OUTPUT_FILE_NAME + output_trials + \".csv\")\n",
    "        return similarity_matrix\n",
    "\n",
    "    def generateResponseMatrix(self):\n",
    "        response_list = self.generateResponseList()\n",
    "        response_list = np.array(response_list)\n",
    "        response_matrix = response_list.reshape(self.number_of_trials,-1)\n",
    "        self.writeDataFile(response_matrix, self.SIM1_OUTPUT_FILE_NAME)\n",
    "\n",
    "    def generateIndexMatrix(self):\n",
    "        \"\"\"return a matrix with the dimensions as number of trials * (number of genomes *\n",
    "            length of SIM1Outputs) contains all the index\"\"\"\n",
    "        index_list = np.arange(0, self.number_of_genomes * self.number_of_trials)\n",
    "        response_matrix = index_list.reshape(self.number_of_trials, -1)\n",
    "        return response_matrix\n",
    "\n",
    "    def generateResponseList(self):\n",
    "        response_list = []\n",
    "        for file in self.simulation_result.keys():\n",
    "            response_list.append(self.simulation_result[file])\n",
    "        return response_list\n",
    "\n",
    "    def computeSimilarityScores(self, response_list, index_matrix, output_type, weight_vector):\n",
    "        kernel = [None]*self.number_of_genomes\n",
    "        for i in range(0, self.number_of_genomes):\n",
    "            kernel[i] = [None]*self.number_of_genomes\n",
    "            kernel[i][i] = 1\n",
    "        if output_type == 'vector':\n",
    "            for i in range(0, self.number_of_genomes - 1):\n",
    "                for j in range(i + 1, self.number_of_genomes):\n",
    "                    total_score = 0\n",
    "                    for k in range(0, self.number_of_trials):\n",
    "                        index1 = index_matrix[k][i]\n",
    "                        index2 = index_matrix[k][j]\n",
    "                        matrix1 = response_list[index1]\n",
    "                        matrix2 = response_list[index2]\n",
    "                        total_score += self.computeSimilarityBetweenVectors(matrix1, matrix2, weight_vector)\n",
    "                    score = total_score / self.number_of_trials\n",
    "                    kernel[i][j] = score\n",
    "                    kernel[j][i] = score\n",
    "        if output_type == 'scalar':\n",
    "            valid_trial_list = self.getValidTrials(response_list, index_matrix)\n",
    "            for i in range(0, self.number_of_genomes - 1):\n",
    "                for j in range(i + 1, self.number_of_genomes):\n",
    "                    num_valid = 0\n",
    "                    count = 0\n",
    "                    for k in valid_trial_list:\n",
    "                        index1 = index_matrix[k][i]\n",
    "                        index2 = index_matrix[k][j]\n",
    "                        if response_list[index1] is not int(-1) and response_list[index2] is not int(-1):\n",
    "                            num_valid = num_valid + 1\n",
    "                            if response_list[index1] == response_list[index2]:\n",
    "                                count = count + 1\n",
    "                    if num_valid == 0:\n",
    "                        score = None\n",
    "                    else:\n",
    "                        score = count / num_valid\n",
    "                    kernel[i][j] = score\n",
    "                    kernel[j][i] = score\n",
    "        return kernel\n",
    "    \n",
    "    def getValidTrials(self, response_list,index_matrix):\n",
    "        valid_trial_list = []\n",
    "        for i in range(0, self.number_of_trials):\n",
    "            index1 = index_matrix[i][0]\n",
    "            for j in range(1, self.number_of_genomes):\n",
    "                index2 = index_matrix[i][j]\n",
    "                if response_list[index1] != response_list[index2]:\n",
    "                    valid_trial_list.append(i)\n",
    "                    break\n",
    "        return valid_trial_list\n",
    "\n",
    "    def computeSimilarityBetweenVectors(self, matrix1, matrix2, weight_vector):\n",
    "        \"\"\"compute the similarity score between two vectors/matrix,\n",
    "        the weight must be a 1*n vector where n is the number of entities\n",
    "        \"\"\"\n",
    "        num_of_entities, num_of_time_points = SafeCastUtil.getMatrixShapeNullSafe(matrix1)\n",
    "        matrix1, matrix2 = self.rescaleVector(matrix1, matrix2)\n",
    "        if weight_vector is None:\n",
    "            similarity = 1 - 1/(num_of_entities * num_of_time_points)*np.sum((matrix1 - matrix2)**2)\n",
    "        else:\n",
    "            similarity = 1 - 1/(num_of_entities * num_of_time_points)*np.sum(np.dot(weight_vector, (matrix1 - matrix2)**2))\n",
    "        return similarity\n",
    "\n",
    "    def rescaleVector(self, matrix1, matrix2):\n",
    "        \"\"\"take two sim1 output and return a rescaled version \"\"\"\n",
    "        max1 = np.amax(matrix1, axis=0, keepdims=True)\n",
    "        max2 = np.amax(matrix2, axis=0, keepdims=True)\n",
    "        max_vector = np.maximum(max1, max2)\n",
    "        max_vector = np.maximum(max_vector, 1e-8)  # TODO Cache the value to improve effieciency\n",
    "        new_matrix1 = matrix1/max_vector\n",
    "        new_matrix2 = matrix2/max_vector\n",
    "        return new_matrix1, new_matrix2\n",
    "\n",
    "    def writeDataFile(self, matrix, file_name):\n",
    "        path = os.getcwd()\n",
    "        OperatingSystemUtil.changeWorkingDirectory(path + self.OUTPUT_FOLDER_NAME)\n",
    "        n = len(matrix)\n",
    "        with open(file_name, 'w') as csv_file:\n",
    "            try:\n",
    "                data_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                for i in range(0, n):\n",
    "                    data_writer.writerow(matrix[i])\n",
    "            finally:\n",
    "                csv_file.close()\n",
    "                os.chdir(path)\n",
    "\n",
    "    @staticmethod\n",
    "    def splitSimilarityMatrixForTraining(similarity_matrix, training_set):\n",
    "        new_matrix = []\n",
    "        for i in range(0, len(training_set)):\n",
    "            new_matrix_row = []\n",
    "            for j in range(0, len(training_set)):\n",
    "                new_matrix_row.append(similarity_matrix[training_set[i], training_set[j]])\n",
    "\n",
    "            new_matrix.append(np.around(new_matrix_row, 2).tolist())\n",
    "        return new_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def splitSimilarityMatrixForTestingAndValidation(similarity_matrix, testing_set, train_length):\n",
    "        testing_matrix = []\n",
    "        for i in range(0, len(testing_set)):\n",
    "            new_matrix_row = []\n",
    "            for j in range(0, train_length):\n",
    "                new_matrix_row.append(similarity_matrix[testing_set[i], j])\n",
    "            testing_matrix.append(new_matrix_row)\n",
    "        return testing_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def trimMatrixForTesting(sub_train_length, testing_matrix):\n",
    "        trimmed_matrix = []\n",
    "        for trim in range(0, len(testing_matrix)):\n",
    "            if len(testing_matrix[trim]) > sub_train_length:\n",
    "                trimmed_matrix.append(testing_matrix[trim][0:sub_train_length])\n",
    "            else:\n",
    "                trimmed_matrix.append(testing_matrix[trim])\n",
    "        return trimmed_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def splitGenomeMatrix(genome_matrix, training_set):\n",
    "        split_matrix = []\n",
    "        for i in range(0, len(training_set)):\n",
    "            split_matrix.append(genome_matrix[training_set[i]])\n",
    "        return split_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5409b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestTrainer(object):\n",
    "\n",
    "    log = logging.getLogger(__name__)\n",
    "    logging.basicConfig()\n",
    "    log.setLevel(logging.INFO)\n",
    "    log.addHandler(logging.StreamHandler())\n",
    "\n",
    "    def __init__(self, genomes_array, third_party_response):\n",
    "        self.genomes_array = genomes_array\n",
    "        self.third_party_response = third_party_response\n",
    "\n",
    "    def trainRandomForest(self, training_set, m_val, max_depth, analysis_type):\n",
    "        max_leaf_nodes = numpy.maximum(2, SafeCastUtil.safeCast(numpy.ceil(max_depth), int))\n",
    "        max_features = SafeCastUtil.safeCast(numpy.floor(m_val), int)\n",
    "        if analysis_type == SupportedAnalysisTypes.CLASSIFICATION:\n",
    "            model = RandomForestClassifier(n_estimators=100, max_leaf_nodes=max_leaf_nodes, max_features=max_features)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=100, max_leaf_nodes=max_leaf_nodes, max_features=max_features)\n",
    "        sample_labels = []\n",
    "        for label in range(0, int(len(training_set))):\n",
    "            sample_labels.append(self.third_party_response[training_set.tolist()[label]])\n",
    "        if len(numpy.unique(sample_labels)) <= 1:\n",
    "            return None\n",
    "        model.fit(self.genomes_array, sample_labels)\n",
    "        self.log.debug(\"Successful creation of Random Forest classifier model: %s\\n\", model)\n",
    "        return model\n",
    "\n",
    "    # TODO: Remove this old code and fix up old ITs referencing it.\n",
    "    def trainRandomForestClassifier(self, pct_train):\n",
    "        if type(self.third_party_response) != list:\n",
    "            response_as_list = self.third_party_response.values()\n",
    "        else:\n",
    "            response_as_list = self.third_party_response\n",
    "        filtered_response = [response for response in response_as_list if int(response) >= 0]\n",
    "        por_success = sum(filtered_response) / len(filtered_response)\n",
    "        self.log.info(\"%s percent 1s \\n%s percent 0s\", str(100 * por_success), str(100 * (1 - por_success)))\n",
    "        [train_y, train_x, test_x, test_y] = self.splitData(filtered_response, self.genomes_array, pct_train)\n",
    "        model = RandomForestClassifier(n_estimators=50)\n",
    "        model.fit(train_x, train_y)\n",
    "        train_predict = model.predict(train_x)\n",
    "        test_predict = model.predict(test_x)\n",
    "        self.log.info(\"Variable importances: %s\", str(model.feature_importances_))\n",
    "        [train_accuracy, test_accuracy, total_accuracy] = self.getAccuraciesForClassifier(train_predict, train_y,\n",
    "                                                                                          test_predict, test_y)\n",
    "\n",
    "        return [model, [train_accuracy, test_accuracy, total_accuracy]]  # Return tuple of model and accuracies\n",
    "\n",
    "    def trainRandomForestRegressor(self, pct_train):\n",
    "        if type(self.third_party_response) != list:\n",
    "            response_as_list = list(self.third_party_response.values())\n",
    "        else:\n",
    "            response_as_list = list(self.third_party_response)\n",
    "        [train_y, train_x, test_x, test_y] = self.splitData(response_as_list, self.genomes_array, pct_train)\n",
    "        model = RandomForestRegressor(n_estimators=50)\n",
    "        model.fit(train_x, train_y)\n",
    "        train_predict = model.predict(train_x)\n",
    "        test_predict = model.predict(test_x)\n",
    "\n",
    "        # Use standard deviation of all results as threshold for \"accurate\". TODO: Consider quelling outliers.\n",
    "        std_dev_of_results = numpy.std(response_as_list)\n",
    "        [train_accuracy, test_accuracy, total_accuracy] = self.getAccuraciesForRegressor(train_predict, train_y,\n",
    "                                                                                         test_predict, test_y,\n",
    "                                                                                         std_dev_of_results)\n",
    "\n",
    "        self.log.info(\"Variable importances: %s\", str(model.feature_importances_))\n",
    "        return [model, [train_accuracy, test_accuracy, total_accuracy]]  # Return tuple of model and accuracies\n",
    "\n",
    "    def splitData(self, responses, data, pct_train):\n",
    "        num_samples = len(data)\n",
    "        num_features = len(data[0])\n",
    "        row_to_split_on = int(round(pct_train * num_samples))\n",
    "        if row_to_split_on == num_samples:\n",
    "            test_x = None\n",
    "            test_y = None\n",
    "            return [responses, data, test_y, test_x]\n",
    "        elif row_to_split_on == 0:\n",
    "            raise ValueError(\"Error: no training data specified. Increase pct_train.\")\n",
    "        else:\n",
    "            train_y = []\n",
    "            train_x = []\n",
    "            test_y = []\n",
    "            test_x = []\n",
    "            for i in range(0, row_to_split_on):\n",
    "                train_y.append(responses[i])\n",
    "                train_x.append([])\n",
    "                for j in range(0, num_features):\n",
    "                    train_x[i].append(data[i][j])\n",
    "            for i in range(row_to_split_on, num_samples):\n",
    "                test_y.append(responses[i])\n",
    "                test_x.append([])\n",
    "                for j in range(0, num_features):\n",
    "                    test_x[i - row_to_split_on].append(data[i][j])\n",
    "            return [train_y, train_x, test_x, test_y]\n",
    "\n",
    "    def getAccuraciesForClassifier(self, train_predict, train_y, test_predict, test_y):\n",
    "\n",
    "        train_length = len(train_y)\n",
    "        matching_train_predictions = self.count_matching_predictions(train_length, train_predict, train_y)\n",
    "\n",
    "        train_accuracy = matching_train_predictions / train_length\n",
    "\n",
    "        test_length = len(test_y)\n",
    "        matching_test_predictions = self.count_matching_predictions(test_length, test_predict, test_y)\n",
    "        test_accuracy = matching_test_predictions / test_length\n",
    "\n",
    "        total_accuracy = (matching_train_predictions + matching_test_predictions) / (train_length + test_length)\n",
    "\n",
    "        self.log.info(\"Training predictions: %s\", str(train_predict))\n",
    "        self.log.info(\"Training accuracy: %s\", str(train_accuracy))\n",
    "        self.log.info(\"Testing predictions: %s\", str(test_predict))\n",
    "        self.log.info(\"Testing accuracy: %s\", str(test_accuracy))\n",
    "        self.log.info(\"Total accuracy: %s\", str(total_accuracy))\n",
    "\n",
    "        return [train_accuracy, test_accuracy, total_accuracy]\n",
    "\n",
    "    def count_matching_predictions(self, data_length, predicted_data, actual_data):\n",
    "        count = 0\n",
    "        for i in range(0, data_length):\n",
    "            if predicted_data[i] == actual_data[i]:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def getAccuraciesForRegressor(self, train_predict, train_y, test_predict, test_y, std_dev):\n",
    "        train_length = len(train_y)\n",
    "        matching_train_predictions = self.count_predictions_within_threshold(train_length, train_predict, train_y, std_dev)\n",
    "\n",
    "        train_accuracy = matching_train_predictions / train_length\n",
    "\n",
    "        test_length = len(test_y)\n",
    "        matching_test_predictions = self.count_predictions_within_threshold(test_length, test_predict, test_y, std_dev)\n",
    "        test_accuracy = matching_test_predictions / test_length\n",
    "\n",
    "        total_accuracy = (matching_train_predictions + matching_test_predictions) / (train_length + test_length)\n",
    "\n",
    "        self.log.info(\"Training predictions: %s\", str(train_predict))\n",
    "        self.log.info(\"Training accuracy: %s\", str(train_accuracy))\n",
    "        self.log.info(\"Testing predictions: %s\", str(test_predict))\n",
    "        self.log.info(\"Testing accuracy: %s\", str(test_accuracy))\n",
    "        self.log.info(\"Total accuracy: %s\", str(total_accuracy))\n",
    "\n",
    "        return [train_accuracy, test_accuracy, total_accuracy]\n",
    "\n",
    "    def count_predictions_within_threshold(self, data_length, predicted_data, actual_data, threshold):\n",
    "        count = 0\n",
    "        for i in range(0, data_length):\n",
    "            if numpy.abs(predicted_data[i] - actual_data[i]) <= threshold:\n",
    "                count += 1\n",
    "        return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportedKernelFunctionTypes:\n",
    "    RADIAL_BASIS_FUNCTION = \"rbf\"\n",
    "    LINEAR = \"linear\"\n",
    "    POLYNOMIAL = \"poly\"\n",
    "    PRECOMPUTED = \"precomputed\"\n",
    "\n",
    "    \n",
    "class SupportVectorMachineTrainer(object):\n",
    "\n",
    "    log = logging.getLogger(__name__)\n",
    "    logging.basicConfig()\n",
    "    log.setLevel(logging.INFO)\n",
    "\n",
    "    def __init__(self, similarity_matrix, third_party_response):\n",
    "        self.matrix = similarity_matrix\n",
    "        self.third_party_response = third_party_response\n",
    "\n",
    "    def trainSupportVectorMachineMultiClassifier(self, training_set, kernel_type, c_value, gamma):\n",
    "        multi_classifier_model = svm.SVC(kernel=kernel_type, C=c_value, gamma=gamma)\n",
    "        sample_labels = []\n",
    "        for label in range(0, int(len(training_set))):\n",
    "            sample_labels.append(self.third_party_response[training_set.tolist()[label]])\n",
    "        if len(np.unique(sample_labels)) <= 1:\n",
    "            return None\n",
    "        multi_classifier_model.fit(self.matrix, sample_labels)\n",
    "        self.log.debug(\"Successful creation of classifier model: %s\\n\", multi_classifier_model)\n",
    "        return multi_classifier_model\n",
    "\n",
    "    def trainSupportVectorMachineRegressor(self, training_set, kernel_type, c_value, gamma, epsilon):\n",
    "        regression_model = svm.SVR(kernel=kernel_type, C=c_value, gamma=gamma, epsilon=epsilon)\n",
    "        sample_labels = []\n",
    "        for label in range(0, int(len(training_set))):\n",
    "            sample_labels.append(self.third_party_response[training_set.tolist()[label]])\n",
    "        if len(np.unique(sample_labels)) <= 1:\n",
    "            return None\n",
    "        regression_model.fit(self.matrix, sample_labels)\n",
    "        self.log.debug(\"Successful creation of classifier model: %s\\n\", regression_model)\n",
    "        return regression_model\n",
    "\n",
    "    def trainSupportVectorMachineForSIM0(self, kernel_type, pct_train):\n",
    "        # Supported kernel types include \"linear,\" \"poly,\" \"rbf,\" \"sigmoid,\" and \"precomputed\"\n",
    "        if (type(self.third_party_response) != np.ndarray) & (type(self.third_party_response) != list):\n",
    "            response_list = []\n",
    "            for file in self.third_party_response.keys():\n",
    "                response_list.append(self.third_party_response[file])\n",
    "        else:\n",
    "            response_list = self.third_party_response\n",
    "\n",
    "        if kernel_type == \"precomputed\":\n",
    "            [train_y, train_X, test_X, test_y] = self.splitMatrix(response_list, self.matrix, pct_train)\n",
    "        else:\n",
    "            [train_y, train_X, test_X, test_y] = self.splitData(response_list, self.matrix, pct_train)\n",
    "\n",
    "        model = SVC(kernel=kernel_type)\n",
    "        if len(np.unique(train_y)) <= 1:\n",
    "            self.log.debug(\"Skipping training, as only class was found.\")\n",
    "            return None\n",
    "        model.fit(train_X, train_y)\n",
    "        trPr = model.predict(train_X)\n",
    "        tePr = model.predict(test_X)\n",
    "        [trAc, teAc, totAc] = self.getAccuracies(trPr, train_y, tePr, test_y)\n",
    "        self.log.info(\"Training predictions: \" + str(trPr))\n",
    "        self.log.info(\"Training accuracy: \" + str(trAc))\n",
    "        self.log.info(\"Testing predictions: \" + str(tePr))\n",
    "        self.log.info(\"Testing accuracy: \" + str(teAc))\n",
    "        self.log.info(\"Overall accuracy: \" + str(totAc))\n",
    "        return [model, [trAc, teAc, totAc]]\n",
    "\n",
    "    def splitMatrix(self, responses, data, pct_train):\n",
    "        tot_data_length = data.__len__()\n",
    "        row_to_split_on = int(round(pct_train * tot_data_length))\n",
    "        if row_to_split_on == tot_data_length:\n",
    "            test_S = None\n",
    "            test_y = None\n",
    "            self.log.info(\"Warning: no testing data specified. Decrease pct_train to fix.\")\n",
    "            return [responses, data, test_S, test_y]\n",
    "        elif row_to_split_on == 0:\n",
    "            self.log.info(\"Error: no training data specified. Increase pct_train.\")\n",
    "        else:\n",
    "            train_y = []\n",
    "            train_S = []\n",
    "            test_y = []\n",
    "            test_S = []\n",
    "            for i in range(0, row_to_split_on):\n",
    "                train_y.append(responses[i])\n",
    "                train_S.append([])\n",
    "                for j in range(0, row_to_split_on):\n",
    "                    train_S[i].append(data[i][j])\n",
    "            for i in range(row_to_split_on, tot_data_length):\n",
    "                test_y.append(responses[i])\n",
    "                test_S.append([])\n",
    "                for j in range(0, train_S.__len__()):\n",
    "                    test_S[i - row_to_split_on].append(data[i][j])\n",
    "            return [train_y, train_S, test_S, test_y]\n",
    "\n",
    "    def splitData(self, responses, data, pct_train):\n",
    "        num_samples = data.__len__()\n",
    "        num_characteristics = data[0].__len__()\n",
    "        row_to_split_on = int(round(pct_train * num_samples))\n",
    "        if row_to_split_on == num_samples:\n",
    "            test_X = None\n",
    "            test_y = None\n",
    "            return [responses, data, test_X, test_y]\n",
    "        elif row_to_split_on == 0:\n",
    "            self.log.info(\"Error: no training data specified. Increase pct_train.\")\n",
    "        else:\n",
    "            train_y = []\n",
    "            train_X = []\n",
    "            test_y = []\n",
    "            test_X = []\n",
    "            for i in range(0, row_to_split_on):\n",
    "                train_y.append(responses[i])\n",
    "                train_X.append([])\n",
    "                for j in range(0, num_characteristics):\n",
    "                    train_X[i].append(data[i][j])\n",
    "            for i in range(row_to_split_on, num_samples):\n",
    "                test_y.append(responses[i])\n",
    "                test_X.append([])\n",
    "                for j in range(0, num_characteristics):\n",
    "                    test_X[i - row_to_split_on].append(data[i][j])\n",
    "            return [train_y, train_X, test_X, test_y]\n",
    "\n",
    "    def getAccuracies(self, trPr, train_y, tePr, test_y):\n",
    "        trLen = train_y.__len__()\n",
    "        count1 = 0\n",
    "        for i in range(0, trLen):\n",
    "            if trPr[i] == train_y[i]:\n",
    "                count1 = count1 + 1\n",
    "\n",
    "        trAc = count1 / trLen\n",
    "\n",
    "        teLen = test_y.__len__()\n",
    "        count2 = 0\n",
    "        for i in range(0, teLen):\n",
    "            if tePr[i] == test_y[i]:\n",
    "                count2 = count2 + 1\n",
    "        teAc = count2 / teLen\n",
    "\n",
    "        totAc = (count1 + count2) / (trLen + teLen)\n",
    "\n",
    "        return [trAc, teAc, totAc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearningDataProcessingService(object):\n",
    "\n",
    "    log = logging.getLogger(__name__)\n",
    "    logging.basicConfig()\n",
    "    log.setLevel(logging.INFO)\n",
    "\n",
    "    def __init__(self, num_permutations):\n",
    "        self.NUM_PERMUTATIONS = num_permutations\n",
    "\n",
    "    TRAINING_PERCENTS = [.2, .4, .6, .8, 1]\n",
    "\n",
    "    def performMachineLearningOnSIM0(self, output_file, genomes_matrix_file, analysis_type, categorical_variables):\n",
    "        responses = self.readCSVFile(output_file)\n",
    "        genome_matrix = self.oneHotEncodeCategoricalVariables(self.readCSVFile(genomes_matrix_file),\n",
    "                                                              categorical_variables)\n",
    "\n",
    "        num_genomes = len(genome_matrix)\n",
    "\n",
    "        order = numpy.random.permutation(num_genomes)\n",
    "\n",
    "        train_length = int(0.5 * num_genomes)\n",
    "        validation_and_testing_length = int(num_genomes / 4)\n",
    "\n",
    "        training_set = order[0:train_length]\n",
    "        validation_set = order[train_length: (train_length + validation_and_testing_length)]\n",
    "        testing_set = order[(train_length + validation_and_testing_length): num_genomes]\n",
    "\n",
    "        training_matrix = MatrixService.splitGenomeMatrix(genome_matrix, training_set)\n",
    "        validation_matrix = MatrixService.splitGenomeMatrix(genome_matrix, validation_set)\n",
    "        testing_matrix = MatrixService.splitGenomeMatrix(genome_matrix, testing_set)\n",
    "\n",
    "        rf_results = self.runRandomForest(responses, testing_matrix, testing_set, train_length,\n",
    "                                          training_matrix, validation_matrix, validation_set, analysis_type)\n",
    "        svm_results_rbf = self.runGenomicSVM(responses, testing_matrix, testing_set, train_length,\n",
    "                                             training_matrix, validation_matrix, validation_set,\n",
    "                                             SupportedKernelFunctionTypes.RADIAL_BASIS_FUNCTION, analysis_type)\n",
    "        svm_results_linear = self.runGenomicSVM(responses, testing_matrix, testing_set, train_length,\n",
    "                                                training_matrix, validation_matrix, validation_set,\n",
    "                                                SupportedKernelFunctionTypes.LINEAR, analysis_type)\n",
    "\n",
    "        full_results = {\n",
    "            \"RF \" + analysis_type: rf_results,\n",
    "            \"SVM \" + analysis_type + \" (RBF)\": svm_results_rbf,\n",
    "            \"SVM \" + analysis_type + \" (LINEAR)\": svm_results_linear\n",
    "        }\n",
    "        self.plotResults(full_results, genomes_matrix_file, analysis_type,  \"SVM and RF \" + analysis_type + \" SIM0 Results\")\n",
    "\n",
    "    def runRandomForest(self, responses, testing_matrix, testing_set, train_length, training_matrix,\n",
    "                        validation_matrix, validation_set, analysis_type):\n",
    "        rf_results = {}\n",
    "        for training_percent in self.TRAINING_PERCENTS:\n",
    "            total_accuracies = []\n",
    "            for i in range(0, self.NUM_PERMUTATIONS):\n",
    "                # further split training matrix.\n",
    "                sub_order = numpy.random.permutation(train_length)\n",
    "                sub_train_length = int(training_percent * train_length)\n",
    "                sub_training_set = sub_order[0:sub_train_length]\n",
    "                split_train_training_matrix = MatrixService.splitGenomeMatrix(numpy.array(training_matrix),\n",
    "                                                                              sub_training_set)\n",
    "\n",
    "                most_accurate_model = self.optimizeHyperparametersForRF(analysis_type, responses,\n",
    "                                                                        split_train_training_matrix, sub_training_set,\n",
    "                                                                        validation_matrix, validation_set)\n",
    "                average_accuracy = self.predictModelAccuracy(most_accurate_model, responses,\n",
    "                                                             testing_matrix, testing_set, analysis_type)\n",
    "                total_accuracies.append(average_accuracy)\n",
    "                rf_results[training_percent] = total_accuracies\n",
    "\n",
    "                self.log.info(\"Average accuracy for round %s of matrix permutations: %s\", i + 1, average_accuracy)\n",
    "                self.manuallyGarbageCollect(most_accurate_model, split_train_training_matrix, sub_order,\n",
    "                                            sub_training_set, sub_train_length)\n",
    "            self.log.info(\"Total accuracy of RF Classifier for all rounds of matrix permutations with %s percent \"\n",
    "                          \"split: %s\", training_percent * 100, numpy.round(numpy.average(total_accuracies), 2))\n",
    "        self.log.debug(\"Accuracies by training percent: %s\", rf_results)\n",
    "        return rf_results\n",
    "\n",
    "    def optimizeHyperparametersForRF(self, analysis_type, responses, training_matrix, training_set,\n",
    "                                     validation_matrix, validation_set):\n",
    "        most_accurate_model = None\n",
    "        most_accurate_model_score = 0\n",
    "        p = len(training_matrix[0])  # number of features\n",
    "        n = len(training_matrix)  # number of samples\n",
    "        for mval in [1, (1 + numpy.sqrt(p)) / 2, numpy.sqrt(p), (numpy.sqrt(p) + p) / 2, p]:\n",
    "            for max_depth in [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1]:\n",
    "                rf_trainer = RandomForestTrainer(training_matrix, responses)\n",
    "                model = rf_trainer.trainRandomForest(training_set, mval, max_depth*n, analysis_type)\n",
    "                model_score = self.predictModelAccuracy(model, responses, validation_matrix,\n",
    "                                                        validation_set, analysis_type)\n",
    "                if model_score <= most_accurate_model_score:\n",
    "                    continue\n",
    "                most_accurate_model_score = model_score\n",
    "                most_accurate_model = model\n",
    "        return most_accurate_model\n",
    "\n",
    "    def runGenomicSVM(self, responses, testing_matrix, testing_set, train_length, training_matrix, validation_matrix,\n",
    "                      validation_set, kernel_type, analysis_type):\n",
    "        svm_results = {}\n",
    "        for training_percent in self.TRAINING_PERCENTS:\n",
    "            total_accuracies = []\n",
    "            for i in range(0, self.NUM_PERMUTATIONS):\n",
    "                # further split training matrix.\n",
    "                sub_order = numpy.random.permutation(train_length)\n",
    "                sub_train_length = int(training_percent * train_length)\n",
    "                sub_training_set = sub_order[0:sub_train_length]\n",
    "                split_train_training_matrix = MatrixService.splitGenomeMatrix(numpy.array(training_matrix),\n",
    "                                                                              sub_training_set)\n",
    "\n",
    "                most_accurate_model = self.optimizeHyperparametersForSVM(kernel_type, analysis_type, responses,\n",
    "                                                                         split_train_training_matrix, sub_training_set,\n",
    "                                                                         validation_matrix, validation_set)\n",
    "\n",
    "                average_accuracy = self.predictModelAccuracy(most_accurate_model, responses,\n",
    "                                                             testing_matrix, testing_set, analysis_type)\n",
    "\n",
    "                self.log.info(\"Average accuracy for round %s of matrix permutations: %s\\n\", i + 1, average_accuracy)\n",
    "                self.manuallyGarbageCollect(most_accurate_model, split_train_training_matrix, sub_order,\n",
    "                                            sub_training_set, sub_train_length)\n",
    "                total_accuracies.append(average_accuracy)\n",
    "                svm_results[training_percent] = total_accuracies\n",
    "            self.log.info(\"Total accuracy of %s SVM %s for all rounds of matrix permutations with %s percent \"\n",
    "                          \"split: %s\", kernel_type, analysis_type, training_percent * 100,\n",
    "                          numpy.round(numpy.average(total_accuracies), 2))\n",
    "        self.log.debug(\"Accuracies by training percent: %s\", svm_results)\n",
    "        return svm_results\n",
    "\n",
    "    def optimizeHyperparametersForSVM(self, kernel_type, analysis_type, responses, training_matrix, sub_training_set,\n",
    "                                      validation_matrix, validation_set):\n",
    "        most_accurate_model = None\n",
    "        most_accurate_model_score = 0\n",
    "        for c_val in [10E-2, 10E-1, 10E0, 10E1, 10E2, 10E3, 10E4, 10E5, 10E6]:\n",
    "            if analysis_type == SupportedAnalysisTypes.CLASSIFICATION:\n",
    "                if kernel_type == SupportedKernelFunctionTypes.RADIAL_BASIS_FUNCTION:\n",
    "                    for gamma in [10E-5, 10E-4, 10E-3, 10E-2, 10E-1, 10E0, 10E1]:\n",
    "                        svm_trainer = SupportVectorMachineTrainer(training_matrix, responses)\n",
    "                        model = svm_trainer.trainSupportVectorMachineMultiClassifier(sub_training_set, kernel_type,\n",
    "                                                                                     c_val, gamma)\n",
    "                        model_score = self.predictModelAccuracy(model, responses, validation_matrix,\n",
    "                                                                validation_set, analysis_type)\n",
    "                        if model_score <= most_accurate_model_score:\n",
    "                            continue\n",
    "                        most_accurate_model = model\n",
    "                        most_accurate_model_score = model_score\n",
    "                else:\n",
    "                    svm_trainer = SupportVectorMachineTrainer(training_matrix, responses)\n",
    "                    model = svm_trainer.trainSupportVectorMachineMultiClassifier(sub_training_set, kernel_type,\n",
    "                                                                                 c_val, 'auto')\n",
    "                    model_score = self.predictModelAccuracy(model, responses, validation_matrix,\n",
    "                                                            validation_set, analysis_type)\n",
    "                    if model_score <= most_accurate_model_score:\n",
    "                        continue\n",
    "                    most_accurate_model = model\n",
    "                    most_accurate_model_score = model_score\n",
    "            elif analysis_type == SupportedAnalysisTypes.REGRESSION:\n",
    "                for epsilon in [0.01, 0.05, 0.1, 0.15, 0.2]:\n",
    "                    if kernel_type == SupportedKernelFunctionTypes.RADIAL_BASIS_FUNCTION:\n",
    "                        for gamma in [10E-5, 10E-4, 10E-3, 10E-2, 10E-1, 10E0, 10E1]:\n",
    "                            svm_trainer = SupportVectorMachineTrainer(training_matrix, responses)\n",
    "                            model = svm_trainer.trainSupportVectorMachineRegressor(sub_training_set, kernel_type,\n",
    "                                                                                   c_val, gamma, epsilon)\n",
    "                            model_score = self.predictModelAccuracy(model, responses, validation_matrix,\n",
    "                                                                    validation_set, analysis_type)\n",
    "                            if model_score <= most_accurate_model_score:\n",
    "                                continue\n",
    "                            most_accurate_model = model\n",
    "                            most_accurate_model_score = model_score\n",
    "                    else:\n",
    "                        svm_trainer = SupportVectorMachineTrainer(training_matrix, responses)\n",
    "                        model = svm_trainer.trainSupportVectorMachineRegressor(sub_training_set, kernel_type,\n",
    "                                                                               c_val, 'auto', epsilon)\n",
    "                        model_score = self.predictModelAccuracy(model, responses, validation_matrix,\n",
    "                                                                validation_set, analysis_type)\n",
    "                        if model_score <= most_accurate_model_score:\n",
    "                            continue\n",
    "                        most_accurate_model = model\n",
    "                        most_accurate_model_score = model_score\n",
    "\n",
    "        return most_accurate_model\n",
    "\n",
    "    def performMachineLearningOnSIM1(self, output_file, similarity_matrix_file, analysis_type):\n",
    "        responses = self.readCSVFile(output_file)\n",
    "        similarity_matrix = self.readCSVFile(similarity_matrix_file)\n",
    "\n",
    "        num_genomes = len(similarity_matrix)\n",
    "        order = numpy.random.permutation(num_genomes)\n",
    "\n",
    "        train_length = int(0.5 * num_genomes)  # half the similarity matrix\n",
    "        validation_and_testing_length = int(num_genomes / 4)  # 1/4 the similarity matrix.\n",
    "\n",
    "        training_set = order[0:train_length]\n",
    "        validation_set = order[train_length: (train_length + validation_and_testing_length)]\n",
    "        testing_set = order[(train_length + validation_and_testing_length): num_genomes]\n",
    "\n",
    "        training_matrix = MatrixService.splitSimilarityMatrixForTraining(similarity_matrix, training_set)\n",
    "        validation_matrix = MatrixService.splitSimilarityMatrixForTestingAndValidation(similarity_matrix,\n",
    "                                                                                       validation_set, train_length)\n",
    "        testing_matrix = MatrixService.splitSimilarityMatrixForTestingAndValidation(similarity_matrix, testing_set,\n",
    "                                                                                    train_length)\n",
    "\n",
    "        kernelized_svm = self.runKernelizedSVM(responses, testing_matrix, testing_set, train_length,\n",
    "                                               training_matrix, validation_matrix, validation_set, analysis_type)\n",
    "        full_results = {\n",
    "            \"KERNELIZED SVM\": kernelized_svm\n",
    "        }\n",
    "\n",
    "        self.plotResults(full_results, similarity_matrix_file, analysis_type, \"SIM1 Kernelized SVM\")\n",
    "\n",
    "    def runKernelizedSVM(self, responses, testing_matrix, testing_set, train_length, training_matrix, validation_matrix,\n",
    "                         validation_set, analysis_type):\n",
    "        results_by_percent_train = {}\n",
    "        for training_percent in self.TRAINING_PERCENTS:\n",
    "            total_accuracies = []\n",
    "            for permutation in range(0, self.NUM_PERMUTATIONS):\n",
    "\n",
    "                # further split training matrix.\n",
    "                sub_order = numpy.random.permutation(train_length)\n",
    "                sub_train_length = int(training_percent * train_length)\n",
    "                sub_training_set = sub_order[0:sub_train_length]\n",
    "                split_train_training_matrix = MatrixService.splitSimilarityMatrixForTraining(\n",
    "                    numpy.array(training_matrix), sub_training_set)\n",
    "\n",
    "                trimmed_validation_matrix = MatrixService.trimMatrixForTesting(sub_train_length, validation_matrix)\n",
    "                trimmed_testing_matrix = MatrixService.trimMatrixForTesting(sub_train_length, testing_matrix)\n",
    "\n",
    "                most_accurate_model = self.optimizeHyperparametersForSVM(SupportedKernelFunctionTypes.RADIAL_BASIS_FUNCTION,\n",
    "                                                                         analysis_type, responses,\n",
    "                                                                         split_train_training_matrix, sub_training_set,\n",
    "                                                                         trimmed_validation_matrix, validation_set)\n",
    "                average_accuracy = self.predictModelAccuracy(most_accurate_model, responses,\n",
    "                                                             trimmed_testing_matrix, testing_set, analysis_type)\n",
    "\n",
    "                self.log.info(\"Average accuracy for round %s of matrix permutations: %s\\n\", permutation + 1,\n",
    "                               average_accuracy)\n",
    "                self.manuallyGarbageCollect(most_accurate_model, split_train_training_matrix, sub_order,\n",
    "                                            sub_training_set, sub_train_length)\n",
    "                total_accuracies.append(average_accuracy)\n",
    "\n",
    "            results_by_percent_train[training_percent] = total_accuracies\n",
    "            self.log.info(\"Total accuracy for all rounds of matrix permutations with %s percent split: %s\",\n",
    "                          training_percent * 100, numpy.round(numpy.average(total_accuracies), 2))\n",
    "        self.log.debug(\"Accuracies by training percent: %s\", results_by_percent_train)\n",
    "        return results_by_percent_train\n",
    "\n",
    "    def performFullSIM0SIM1Analysis(self, output_file, genomes_matrix_file, similarity_matrix_file, analysis_type,\n",
    "                                    categorical_variables):\n",
    "        responses = self.readCSVFile(output_file)\n",
    "        genomes_matrix = self.oneHotEncodeCategoricalVariables(self.readCSVFile(genomes_matrix_file),\n",
    "                                                               categorical_variables)\n",
    "        similarity_matrix = self.readCSVFile(similarity_matrix_file)\n",
    "\n",
    "        num_genomes = len(genomes_matrix)\n",
    "\n",
    "        order = numpy.random.permutation(num_genomes)\n",
    "\n",
    "        train_length = int(0.5 * num_genomes)\n",
    "        validation_and_testing_length = int(num_genomes / 4)\n",
    "\n",
    "        training_set = order[0:train_length]\n",
    "        validation_set = order[train_length: (train_length + validation_and_testing_length)]\n",
    "        testing_set = order[(train_length + validation_and_testing_length): num_genomes]\n",
    "\n",
    "        genomic_training_matrix = MatrixService.splitGenomeMatrix(genomes_matrix, training_set)\n",
    "        genomic_validation_matrix = MatrixService.splitGenomeMatrix(genomes_matrix, validation_set)\n",
    "        genomic_testing_matrix = MatrixService.splitGenomeMatrix(genomes_matrix, testing_set)\n",
    "\n",
    "        kernel_training_matrix = MatrixService.splitSimilarityMatrixForTraining(similarity_matrix, training_set)\n",
    "        kernel_validation_matrix = MatrixService.splitSimilarityMatrixForTestingAndValidation(similarity_matrix,\n",
    "                                                                                              validation_set,\n",
    "                                                                                              train_length)\n",
    "        kernel_testing_matrix = MatrixService.splitSimilarityMatrixForTestingAndValidation(similarity_matrix,\n",
    "                                                                                           testing_set,\n",
    "                                                                                           train_length)\n",
    "\n",
    "        rf_genomic_results = self.runRandomForest(responses, genomic_testing_matrix, testing_set,\n",
    "                                                  train_length, genomic_training_matrix,\n",
    "                                                  genomic_validation_matrix, validation_set, analysis_type)\n",
    "\n",
    "        svm_genomic_results_rbf = self.runGenomicSVM(responses, genomic_testing_matrix, testing_set,\n",
    "                                                     train_length, genomic_training_matrix,\n",
    "                                                     genomic_validation_matrix, validation_set,\n",
    "                                                     SupportedKernelFunctionTypes.RADIAL_BASIS_FUNCTION, analysis_type)\n",
    "\n",
    "        svm_genomic_results_linear = self.runGenomicSVM(responses, genomic_testing_matrix, testing_set,\n",
    "                                                        train_length, genomic_training_matrix,\n",
    "                                                        genomic_validation_matrix, validation_set,\n",
    "                                                        SupportedKernelFunctionTypes.LINEAR, analysis_type)\n",
    "\n",
    "        svm_kernel_results = self.runKernelizedSVM(responses, kernel_testing_matrix, testing_set,\n",
    "                                                   train_length, kernel_training_matrix,\n",
    "                                                   kernel_validation_matrix, validation_set, analysis_type)\n",
    "        full_results = {\n",
    "            \"RF SIM0 \" + analysis_type: rf_genomic_results,\n",
    "            \"SVM SIM0 \" + analysis_type + \" (RBF)\": svm_genomic_results_rbf,\n",
    "            \"SVM SIM0 \" + analysis_type + \" (LINEAR)\": svm_genomic_results_linear,\n",
    "            \"SVM SIM1 \" + analysis_type: svm_kernel_results\n",
    "        }\n",
    "        self.plotResults(full_results, genomes_matrix_file, analysis_type, \"SIM0 SIM1 Combined Results\")\n",
    "\n",
    "    def readCSVFile(self, file):\n",
    "        return numpy.loadtxt(open(file, \"rb\"), delimiter=\",\")\n",
    "\n",
    "    def oneHotEncodeCategoricalVariables(self, genomes_matrix, categorical_variables):\n",
    "        if categorical_variables is None or len(categorical_variables) == 0:\n",
    "            return genomes_matrix\n",
    "        encoded_matrix = []  # List of lists\n",
    "        for genome in genomes_matrix:\n",
    "            encoded_matrix.append(list(genome))\n",
    "        sorted_deduped_variables = numpy.sort(numpy.unique(categorical_variables))[::-1]\n",
    "        for variable_raw in sorted_deduped_variables:\n",
    "            categorical_variable = SafeCastUtil.safeCast(variable_raw, int)\n",
    "            if categorical_variable is None:\n",
    "                self.log.warning(\"Aborting one-hot-encoding. Non-integer categorical variable index detected.\")\n",
    "            if len(encoded_matrix[0]) > categorical_variable > 0:\n",
    "                assigned_values = []\n",
    "                for genome in encoded_matrix:\n",
    "                    value = genome[categorical_variable]\n",
    "                    if SafeCastUtil.safeCast(value, int) is None:\n",
    "                        self.log.warning(\"Aborting one-hot-encoding. Non integer value for categorical variable \"\n",
    "                                         \"detected.\")\n",
    "                        return genomes_matrix\n",
    "                    if value not in assigned_values:\n",
    "                        assigned_values.append(value)\n",
    "                assigned_values = numpy.sort(assigned_values)\n",
    "\n",
    "                for matrix_row in range(0, len(encoded_matrix)):\n",
    "                    for feature_index in range(0, len(encoded_matrix[matrix_row])):\n",
    "                        if feature_index == categorical_variable:\n",
    "                            value_as_multiple_categories = []\n",
    "                            for assigned_value in assigned_values:\n",
    "                                boolean_value = 0\n",
    "                                if assigned_value == encoded_matrix[matrix_row][feature_index]:\n",
    "                                    boolean_value = 1\n",
    "                                value_as_multiple_categories.append(boolean_value)\n",
    "                            new_genome = numpy.concatenate((encoded_matrix[matrix_row][:categorical_variable],\n",
    "                                                            value_as_multiple_categories,\n",
    "                                                            encoded_matrix[matrix_row][categorical_variable + 1:]))\n",
    "                            encoded_matrix[matrix_row] = new_genome\n",
    "        return encoded_matrix\n",
    "\n",
    "    def predictModelAccuracy(self, model, responses, testing_matrix, testing_set, analysis_type):\n",
    "        if model is None:\n",
    "            return 0\n",
    "        predictions = model.predict(testing_matrix)\n",
    "        if analysis_type == SupportedAnalysisTypes.REGRESSION:\n",
    "            real_responses = []\n",
    "            corresponding_predictions = []\n",
    "            for i in range(0, len(predictions)):\n",
    "                genome = testing_set[i]\n",
    "                real_responses.append(responses[genome])\n",
    "                corresponding_predictions.append(predictions[i])\n",
    "            return r2_score(real_responses, corresponding_predictions)\n",
    "        else:\n",
    "            accuracies = []\n",
    "            for i in range(0, len(predictions)):\n",
    "                genome = testing_set[i]\n",
    "                real_response = responses[genome]\n",
    "                prediction = predictions[i]\n",
    "                accuracy = 0\n",
    "                if real_response == prediction:\n",
    "                    accuracy = 1\n",
    "                accuracies.append(accuracy)\n",
    "                self.log.debug(\"Predicted outcome for genome %s vs actual outcome: %s vs %s\", genome, prediction,\n",
    "                               real_response)\n",
    "            average_accuracy = numpy.average(accuracies)\n",
    "            return average_accuracy\n",
    "\n",
    "    def plotResults(self, full_results, csv_file_location, analysis_type, title):\n",
    "        try:\n",
    "            output_path = \"\"\n",
    "            csv_path_split = csv_file_location.split(\"/\")\n",
    "            for i in range(1, len(csv_path_split) - 1):\n",
    "                output_path += \"/\" + csv_path_split[i]\n",
    "            graphing_service = GraphingService()\n",
    "            graphing_service.makeMultiBarPlotWithMultipleAnalysis(full_results, output_path, analysis_type, title)\n",
    "        except Exception as exception:\n",
    "            self.log.error(\"Unable to create or save graphs due to: %s\", exception)\n",
    "\n",
    "    def manuallyGarbageCollect(self, most_accurate_model, split_train_training_matrix, sub_order, sub_training_set,\n",
    "                               sub_train_length):\n",
    "        GarbageCollectionUtility.logMemoryUsageAndGarbageCollect(self.log)\n",
    "        del most_accurate_model\n",
    "        del split_train_training_matrix\n",
    "        del sub_order\n",
    "        del sub_training_set\n",
    "        del sub_train_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8e020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a44b8191",
   "metadata": {},
   "source": [
    "# SIM0 ML\n",
    "Files needed -> SIM0output.csv , SIM0GenomeMatrix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGenomesSIM0(file_extension, input_file, path, number_of_genomes, response_type):\n",
    "    with open(input_file) as data_file:\n",
    "        try:\n",
    "            genomes = processInputFileAndCreateGenomes(data_file, file_extension, path, number_of_genomes)\n",
    "            third_party_result = callThirdPartyService(file_extension, path, genomes[0], True, number_of_genomes,\n",
    "                                                       0, response_type)\n",
    "            logg.info(\"Results of third party call: %s\", third_party_result)\n",
    "        except ValueError as valueError:\n",
    "            logg.error(valueError)\n",
    "        finally:\n",
    "            logg.debug(\"Closing file %s\", input_file)\n",
    "            data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processInputFileAndCreateGenomes(data_file, file_extension, path, number_of_genomes):\n",
    "    file_parsing_service = FileProcessingService(data_file, file_extension, number_of_genomes, path)\n",
    "    return file_parsing_service.createGenomes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53778c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callThirdPartyService(file_extension, path, file_list, record_output, number_of_genomes, number_of_trials,\n",
    "                          response_type):\n",
    "    third_party_caller_service = ThirdPartyProgramCaller(path, file_extension, file_list, response_type,\n",
    "                                                         number_of_genomes, number_of_trials)\n",
    "    return third_party_caller_service.callThirdPartyProgram(record_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c439c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = os.path.abspath('./')\n",
    "print(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a7532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sim 0 genomes Creation\n",
    "input_file = os.path.abspath('./Model/linearProgrammingModel.octave')\n",
    "# input_file = os.path.abspath('./Model/linearProgrammingModelWithVectorResponse.octave')\n",
    "number_of_genomes = 500\n",
    "response_type = 'int'\n",
    "output_path = os.path.abspath('./Model')\n",
    "file_extension = input_file.split(\".\")[1]\n",
    "createGenomesSIM0(file_extension, input_file, output_path, number_of_genomes, response_type)\n",
    "\n",
    "sim0_output_file_path = os.path.abspath('./Model/GenomeFiles/SimulationOutputs/Sim0Output.csv')\n",
    "shutil.copy(sim0_output_file_path, os.path.abspath('./DataReadyForML'))\n",
    "sim0_genome_file_path = os.path.abspath('./Model/GenomeFiles/Sim0GenomesMatrix.csv')\n",
    "shutil.copy(sim0_genome_file_path, os.path.abspath('./DataReadyForML'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424157f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "Memory usage for PID 10201: 185.21: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.21: MB\n",
      "Total accuracy of RF Classifier for all rounds of matrix permutations with 20.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of RF Classifier for all rounds of matrix permutations with 20.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "Memory usage for PID 10201: 185.21: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.21: MB\n",
      "Total accuracy of RF Classifier for all rounds of matrix permutations with 40.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of RF Classifier for all rounds of matrix permutations with 40.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "Memory usage for PID 10201: 185.21: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.21: MB\n",
      "Total accuracy of RF Classifier for all rounds of matrix permutations with 60.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of RF Classifier for all rounds of matrix permutations with 60.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "Memory usage for PID 10201: 185.21: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.21: MB\n",
      "Total accuracy of RF Classifier for all rounds of matrix permutations with 80.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of RF Classifier for all rounds of matrix permutations with 80.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of RF Classifier for all rounds of matrix permutations with 100 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of RF Classifier for all rounds of matrix permutations with 100 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 20.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 20.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 40.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 40.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 60.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 60.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 80.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 80.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 100 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of rbf SVM CLASSIFICATION for all rounds of matrix permutations with 100 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of linear SVM CLASSIFICATION for all rounds of matrix permutations with 20.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of linear SVM CLASSIFICATION for all rounds of matrix permutations with 20.0 percent split: 0.78\n",
      "Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.776\n",
      "\n",
      "Memory usage for PID 10201: 186.22: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 186.22: MB\n",
      "Total accuracy of linear SVM CLASSIFICATION for all rounds of matrix permutations with 40.0 percent split: 0.78\n",
      "INFO:__main__:Total accuracy of linear SVM CLASSIFICATION for all rounds of matrix permutations with 40.0 percent split: 0.78\n"
     ]
    }
   ],
   "source": [
    "# output_file = os.path.abspath('./DataReadyForML/Master/Sim0Output.csv')\n",
    "# genomes_matrix_file = os.path.abspath('./DataReadyForML/Master/Sim0GenomesMatrix.csv')\n",
    "output_file = os.path.abspath('./DataReadyForML/Sim0Output.csv')\n",
    "genomes_matrix_file = os.path.abspath('./DataReadyForML/Sim0GenomesMatrix.csv')\n",
    "analysis_type = 'CLASSIFICATION' # REGRESSION or CLASSIFICATION\n",
    "indices = []\n",
    "\n",
    "# Number of permutations we need\n",
    "num_permutations = 1\n",
    "\n",
    "data_processor = MachineLearningDataProcessingService(num_permutations)\n",
    "data_processor.performMachineLearningOnSIM0(output_file, genomes_matrix_file, analysis_type, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGenomesSIM1(file_extension, input_file, path, number_of_genomes, number_of_trials, response_type):\n",
    "    with open(input_file) as data_file:\n",
    "        try:\n",
    "            trial_files = createTrialFiles(data_file, file_extension, number_of_genomes, number_of_trials, path)\n",
    "            third_party_result = callThirdPartyService(file_extension, path, trial_files, False,\n",
    "                                                       number_of_genomes, number_of_trials, response_type)\n",
    "            logg.info(\"Results of third party call: %s\", third_party_result)\n",
    "        except ValueError as valueError:\n",
    "            logg.error(valueError)\n",
    "        finally:\n",
    "            logg.debug(\"Closing file %s\", input_file)\n",
    "            data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrialFiles(data_file, file_extension, number_of_genomes, number_of_trials, path):\n",
    "    process_trial_files = Sim1FileProcessingService(data_file, file_extension, number_of_genomes,\n",
    "                                                    number_of_trials, path)\n",
    "    trial_files = process_trial_files.createTrialFiles()\n",
    "    logg.info(\"Created all the trial files\")\n",
    "    return trial_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8ef91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create genomes SIM1\n",
    "input_file = os.path.abspath('./Model/linearProgrammingModelSim1.octave')\n",
    "number_of_genomes = 500\n",
    "number_of_trials = 10\n",
    "response_type = 'int'\n",
    "output_path = os.path.abspath('./Model')\n",
    "file_extension = input_file.split(\".\")[1]\n",
    "createGenomesSIM1(file_extension, input_file, output_path, number_of_genomes, number_of_trials, response_type)\n",
    "\n",
    "sim1_simialarity_file_path = os.path.abspath('./Model/GenomeFiles/SimilarityMatrix/Sim1SimilarityMatrixfinal.csv')\n",
    "shutil.copy(sim1_simialarity_file_path, os.path.abspath('./DataReadyForML'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ae5fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anshudhar2001/Desktop/Repos/SimKernProject/DataReadyForML/Sim1SimilarityMatrixfinal.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USE THIS IF YOU WANT TO MANUALLY UPDATE DATA FILES FOR ML PART\n",
    "\n",
    "# sim0_output_file_path = os.path.abspath('./Model/GenomeFiles/SimulationOutputs/Sim0Output.csv')\n",
    "# shutil.copy(sim0_output_file_path, os.path.abspath('./DataReadyForML'))\n",
    "# sim0_genome_file_path = os.path.abspath('./Model/GenomeFiles/Sim0GenomesMatrix.csv')\n",
    "# shutil.copy(sim0_genome_file_path, os.path.abspath('./DataReadyForML'))\n",
    "# sim1_simialarity_file_path = os.path.abspath('./Model/GenomeFiles/SimilarityMatrix/Sim1SimilarityMatrixfinal.csv')\n",
    "# shutil.copy(sim1_simialarity_file_path, os.path.abspath('./DataReadyForML'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d65f5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Total accuracy for all rounds of matrix permutations with 20.0 percent split: 0.86\n",
      "INFO:__main__:Total accuracy for all rounds of matrix permutations with 20.0 percent split: 0.86\n",
      "Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Total accuracy for all rounds of matrix permutations with 40.0 percent split: 0.86\n",
      "INFO:__main__:Total accuracy for all rounds of matrix permutations with 40.0 percent split: 0.86\n",
      "Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 184.57: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 184.57: MB\n",
      "Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.1: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.1: MB\n",
      "Total accuracy for all rounds of matrix permutations with 60.0 percent split: 0.86\n",
      "INFO:__main__:Total accuracy for all rounds of matrix permutations with 60.0 percent split: 0.86\n",
      "Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.36: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.36: MB\n",
      "Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Total accuracy for all rounds of matrix permutations with 80.0 percent split: 0.86\n",
      "INFO:__main__:Total accuracy for all rounds of matrix permutations with 80.0 percent split: 0.86\n",
      "Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 1 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 2 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 3 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 4 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 5 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 6 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 7 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 8 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 9 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "INFO:__main__:Average accuracy for round 10 of matrix permutations: 0.856\n",
      "\n",
      "Memory usage for PID 10201: 185.63: MB\n",
      "INFO:__main__:Memory usage for PID 10201: 185.63: MB\n",
      "Total accuracy for all rounds of matrix permutations with 100 percent split: 0.86\n",
      "INFO:__main__:Total accuracy for all rounds of matrix permutations with 100 percent split: 0.86\n",
      "/tmp/ipykernel_10201/1260802541.py:44: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  basic_plot.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ML on SIM1 genomes\n",
    "# output_file = os.path.abspath('./DataReadyForML/Master/Sim0Output.csv')\n",
    "# sim1_similarity_matrix_file = os.path.abspath('./DataReadyForML/Master/Sim1SimilarityMatrixfinal.csv')\n",
    "output_file = os.path.abspath('./DataReadyForML/Sim0Output.csv')\n",
    "sim1_similarity_matrix_file = os.path.abspath('./DataReadyForML/Sim1SimilarityMatrixfinal.csv')\n",
    "analysis_type = 'CLASSIFICATION' # REGRESSION or CLASSIFICATION\n",
    "\n",
    "num_permutations = 100\n",
    "\n",
    "data_processor = MachineLearningDataProcessingService(num_permutations)\n",
    "data_processor.performMachineLearningOnSIM1(output_file, sim1_similarity_matrix_file, analysis_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200e19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
